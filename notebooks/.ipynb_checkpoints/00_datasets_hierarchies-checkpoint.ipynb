{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Prototype Dataset Hierarchy\n",
    "## MKDG\n",
    "This notebook constructs a hierarchy of datasets from full MOM6 outputs:\n",
    "- Full (944 GB)\n",
    "- Mini (87 GB)\n",
    "- Micro (few GBs)\n",
    "- Pico (100â€“200 MB)\n",
    "- Pico one-year (30 MB)\n",
    "\n",
    "Purpose:\n",
    "- Enable fast prototyping and LLM-assisted code development on small subsets\n",
    "- Ensure realistic tests on micro/mini before full-scale training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks/01_build_dataset_hierarchy.ipynb\n",
    "\n",
    "import xarray as xr\n",
    "import pathlib\n",
    "\n",
    "# Paths\n",
    "\n",
    "PROTOTYPE_DIR = pathlib.Path(\"../../prototypes_dataset/\")\n",
    "PROTOTYPE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load full dataset (~ 1 Tb)\n",
    "path = \"../../9km_monthly_gyre/train/\"\n",
    "\n",
    "ds = xr.open_mfdataset(\n",
    "    path+\"*\", \n",
    "    combine='by_coords',decode_times=True)\n",
    "\n",
    "# Take only first 1000 meters\n",
    "ds = ds.sel(z_l=slice(None,1000))\n",
    "\n",
    "# Now AOU is is mol/kg, because of dimensional consistency with AOU we need to put DIC and O2 in micromol/kg  \n",
    "# Compute net heat flux positive IN the ocean \n",
    "ds[\"Qnet\"] = ds[\"SW\"]-ds[\"LW\"]-ds[\"latent\"]-ds[\"sensible\"]\n",
    "\n",
    "\n",
    "# --- Mini dataset: remove boundary regions ---\n",
    "ds_mini = ds.sel(\n",
    "    yh=slice(25.0, 55.0),\n",
    "    xh=slice(-45.0, -25.0),\n",
    "    z_l=slice(0, 500)   # adjust as desired\n",
    ")\n",
    "ds_mini.to_netcdf(PROTOTYPE_DIR / \"ds_mini.nc\")\n",
    "ds_mini_surf = ds_mini.isel(z_l=0)\n",
    "ds_mini_surf.to_netcdf(PROTOTYPE_DIR / \"ds_mini_surf.nc\")\n",
    "\n",
    "# --- Micro dataset: smaller cutout ---\n",
    "ds_micro = ds_mini.sel(xh=slice(-35, -30), yh=slice(35, 50))\n",
    "ds_micro.to_netcdf(PROTOTYPE_DIR / \"ds_micro.nc\")\n",
    "ds_micro_surf = ds_micro.isel(z_l=0)\n",
    "ds_micro_surf.to_netcdf(PROTOTYPE_DIR / \"ds_micro_surf.nc\")\n",
    "\n",
    "# --- Nano dataset: smallest extract ---\n",
    "ds_nano = ds_mini.sel(xh=slice(-34, -33), yh=slice(43, 44))\n",
    "ds_nano.to_netcdf(PROTOTYPE_DIR / \"ds_nano.nc\")\n",
    "ds_nano_surf = ds_nano.isel(z_l=0)\n",
    "ds_nano_surf.to_netcdf(PROTOTYPE_DIR / \"ds_nano_surf.nc\")\n",
    "\n",
    "# --- Temporal subsets of Nano ---\n",
    "ds_nano_surf_three_years = ds_nano_surf.sel(\n",
    "    time=ds_nano_surf['time'].dt.year.isin([2016, 2017, 2018])\n",
    ")\n",
    "ds_nano_surf_three_years.to_netcdf(PROTOTYPE_DIR / \"ds_nano_surf_three_years.nc\")\n",
    "\n",
    "ds_nano_surf_one_year = ds_nano_surf.sel(\n",
    "    time=ds_nano_surf['time'].dt.year.isin([2016])\n",
    ")\n",
    "ds_nano_surf_one_year.to_netcdf(PROTOTYPE_DIR / \"ds_nano_surf_one_year.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, numpy as np, math\n",
    "from pathlib import Path\n",
    "\n",
    "def _to_python(obj):\n",
    "    \"\"\"Recursively convert NumPy/Pandas objects to pure Python and scrub NaNs.\"\"\"\n",
    "    if isinstance(obj, np.generic):\n",
    "        obj = obj.item()\n",
    "    if isinstance(obj, float):\n",
    "        if math.isnan(obj):\n",
    "            return None\n",
    "        if math.isinf(obj):\n",
    "            return str(obj)\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): _to_python(v) for k,v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple, set, np.ndarray)):\n",
    "        return [_to_python(x) for x in obj]\n",
    "    return obj\n",
    "\n",
    "def write_schema(ds, out_path, notes=None):\n",
    "    \"\"\"\n",
    "    Generate schema.yaml for a given xarray.Dataset.\n",
    "    - Extracts coords and variables\n",
    "    - Supplements units/long_names for key BGC variables\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"coords\": {},\n",
    "        \"variables\": {},\n",
    "        \"io_hints\": {\n",
    "            \"suggested_chunks\": {dim: min(size, 128) for dim, size in ds.sizes.items()},\n",
    "            \"compression\": {\"zlib\": True, \"complevel\": 4}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for c in ds.coords:\n",
    "        da = ds[c]\n",
    "        schema[\"coords\"][c] = {\n",
    "            \"dims\": list(da.dims),\n",
    "            \"dtype\": str(da.dtype),\n",
    "            **{k: v for k, v in da.attrs.items() if v not in (None,\"\")}\n",
    "        }\n",
    "\n",
    "    for v in ds.data_vars:\n",
    "        da = ds[v]\n",
    "        meta = {\n",
    "            \"dims\": list(da.dims),\n",
    "            \"dtype\": str(da.dtype),\n",
    "            **{k: v2 for k,v2 in da.attrs.items() if v2 not in (None,\"\")}\n",
    "        }\n",
    "        # Standardize key biogeochemical variables\n",
    "        if v in [\"o2\", \"dic\", \"O2sat\", \"AOU\"]:\n",
    "            meta[\"units\"] = \"mol kg-1\"\n",
    "        if v == \"CT\":\n",
    "            meta[\"units\"] = \"degC\"\n",
    "            meta[\"notes\"] = \"Computed using TEOS-10: gsw.CT_from_t(SA, temp, pressure)\"\n",
    "\n",
    "        schema[\"variables\"][v] = meta\n",
    "\n",
    "    if notes:\n",
    "        schema[\"notes\"] = notes\n",
    "\n",
    "    # Save schema\n",
    "    Path(out_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "    with open(out_path, \"w\") as f:\n",
    "        yaml.safe_dump(_to_python(schema), f, sort_keys=False)\n",
    "    print(f\"Schema written to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write schemas on all datasets\n",
    "# Mini dataset\n",
    "write_schema(ds_mini, PROTOTYPE_DIR / \"schema_ds_mini.yaml\")\n",
    "\n",
    "# Micro dataset\n",
    "write_schema(ds_micro, PROTOTYPE_DIR / \"schema_ds_micro.yaml\")\n",
    "\n",
    "# Pico dataset\n",
    "write_schema(ds_pico, PROTOTYPE_DIR / \"schema_ds_pico.yaml\")\n",
    "\n",
    "# Pico surf one-year\n",
    "write_schema(ds_pico_surf_one_year, PROTOTYPE_DIR / \"schema_ds_pico_surf_one_year.yaml\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
